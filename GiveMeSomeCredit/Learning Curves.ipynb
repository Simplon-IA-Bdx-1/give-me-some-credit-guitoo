{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame, read_csv, to_numeric\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from pickle import load, dump\n",
    "from bigml.api import BigML\n",
    "import kaggle\n",
    "from pprint import pprint\n",
    "from os import path\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "big_ml_project = 'project/5d94a428eba31d460c00023f'\n",
    "api = BigML(project=big_ml_project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "project = 'gmsc'\n",
    "version = 'learning-curve'\n",
    "jar_filename = project + '-' + version + '-picklejar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def data_save(project_data):\n",
    "    with open(jar_filename, 'wb') as file:\n",
    "        dump(project_data,file)\n",
    "def data_load():\n",
    "    if path.exists(jar_filename):\n",
    "        with open(jar_filename, 'rb') as file:\n",
    "            project_data = load(file)\n",
    "        return project_data\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "project_data = data_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "project_data['fulltrain file']='cs-train.csv'\n",
    "project_data['test file']='cs-test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fulltrain=read_csv('./cs-training.csv',index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120000"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fixed_seed=12345\n",
    "train, valid = train_test_split(fulltrain, test_size=0.2, random_state=fixed_seed)\n",
    "valid_filename = project + '-' + version + '-valid' + '.csv.bz2'\n",
    "valid.to_csv(valid_filename,index_label='Id')\n",
    "train_filename = project + '-' + version + '-train' + '.csv.bz2'\n",
    "train.to_csv(train_filename,index_label='Id')\n",
    "project_data['validation file'] = valid_filename\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "if 'models' not in project_data:\n",
    "    project_data['models']={}\n",
    "if 'train sources' not in project_data:\n",
    "    project_data['train sources']={}\n",
    "if 'train datasets' not in project_data:\n",
    "    project_data['train datasets']={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "data_save(project_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'source/5dc037487811dd7f2d0103f2'\n"
     ]
    }
   ],
   "source": [
    "if 'validation source' not in project_data:\n",
    "    valid_src = api.create_source(valid_filename)\n",
    "    api.ok(valid_src)\n",
    "    project_data['validation source']=valid_src['resource']\n",
    "else:\n",
    "    valid_src = api.get_source(project_data['validation source'])\n",
    "pprint(valid_src['resource'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'dataset/5dc0374e7811dd05540010c3'\n"
     ]
    }
   ],
   "source": [
    "if 'validation dataset' not in project_data:\n",
    "    valid_ds = api.create_dataset(valid_src)\n",
    "    api.ok(valid_ds)\n",
    "    project_data['validation dataset']=valid_ds['resource']\n",
    "else:\n",
    "    valid_ds = api.get_dataset(project_data['validation dataset'])\n",
    "pprint(valid_ds['resource'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fulltrain file': 'cs-train.csv',\n",
      " 'models': {},\n",
      " 'test file': 'cs-test.csv',\n",
      " 'train datasets': {},\n",
      " 'train sources': {},\n",
      " 'validation dataset': 'dataset/5dc0374e7811dd05540010c3',\n",
      " 'validation file': 'gmsc-learning-curve-valid.csv.bz2',\n",
      " 'validation source': 'source/5dc037487811dd7f2d0103f2'}\n"
     ]
    }
   ],
   "source": [
    "pprint(project_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#training_sizes=[500,2000,5000,10000,25000,50000,100000,150000]\n",
    "training_sizes=[int(120000*i/10) for i in range(1,11) ]\n",
    "models=['ensemble','deepnet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in training_sizes:\n",
    "    train_filename = project + '-' + version + '-train-' + str(size) + '.csv.bz2'\n",
    "    if not path.exists(train_filename):\n",
    "        #if size < 120000:\n",
    "        #    print(size)\n",
    "        train_partial = train.sample(size)\n",
    "        #else:\n",
    "        #    train_partial = train\n",
    "        train_partial.to_csv(train_filename, index_label='Id')\n",
    "        \n",
    "    if size not in project_data['train sources']:\n",
    "        train_src = api.create_source(train_filename)\n",
    "        api.ok(train_src)\n",
    "        project_data['train sources'][size]=train_src['resource']\n",
    "    else:\n",
    "        train_src = api.get_source(project_data['train sources'][size])\n",
    "        \n",
    "    if size not in project_data['train datasets']:\n",
    "        train_ds = api.create_dataset(train_src)\n",
    "        api.ok(train_ds)\n",
    "        project_data['train datasets'][size]=train_ds['resource']\n",
    "    else:\n",
    "        train_ds = api.get_dataset(project_data['train datasets'][size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_save(project_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in training_sizes:\n",
    "    for model_type in models:\n",
    "        if size not in project_data['models']:\n",
    "            project_data['models'][size]={}\n",
    "        if model_type not in project_data['models'][size]:\n",
    "            project_data['models'][size][model_type]={}\n",
    "        model = project_data['models'][size][model_type]\n",
    "        model['size'] = size\n",
    "        model['model type'] = model_type\n",
    "        model['train source'] = project_data['train sources'][size]\n",
    "        model['train dataset'] = project_data['train datasets'][size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ensemble-12000\n",
      "Done\n",
      "Training deepnet-12000\n",
      "Done\n",
      "Training ensemble-24000\n",
      "Done\n",
      "Training deepnet-24000\n",
      "Done\n",
      "Training ensemble-36000\n",
      "Done\n",
      "Training deepnet-36000\n",
      "Done\n",
      "Training ensemble-48000\n",
      "Done\n",
      "Training deepnet-48000\n",
      "Done\n",
      "Training ensemble-60000\n",
      "Done\n",
      "Training deepnet-60000\n",
      "Done\n",
      "Training ensemble-72000\n",
      "Done\n",
      "Training deepnet-72000\n",
      "Done\n",
      "Training ensemble-84000\n",
      "Done\n",
      "Training deepnet-84000\n"
     ]
    }
   ],
   "source": [
    "model_args= {\"objective_field\": \"SeriousDlqin2yrs\"}\n",
    "for size in project_data['models']:\n",
    "    for model_type in project_data['models'][size]:\n",
    "        print('Training ' + model_type + '-' + str(size))\n",
    "        model_data = project_data['models'][size][model_type]\n",
    "        train_ds = model_data['train dataset']\n",
    "        if 'bigml model' not in model_data:\n",
    "            if model_type == 'ensemble':\n",
    "                model = api.create_ensemble(train_ds, model_args)\n",
    "                api.ok(model)\n",
    "                model_data['bigml model'] = model['resource']\n",
    "            elif model_type == 'deepnet':\n",
    "                model = api.create_deepnet(train_ds, model_args)\n",
    "                api.ok(model)\n",
    "                model_data['bigml model'] = model['resource']\n",
    "        print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_save(project_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for size in project_data['models']:\n",
    "    for model_type in project_data['models'][size]:\n",
    "        print('Evaluating ' + model_type + '-' + str(size))\n",
    "        model_data = project_data['models'][size][model_type]\n",
    "        if model_type == 'ensemble':\n",
    "            model = api.get_ensemble(model_data['bigml model'])\n",
    "        if model_type == 'deepnet':\n",
    "            model = api.get_deepnet(model_data['bigml model'])\n",
    "        if 'valid evaluation' not in model_data:\n",
    "            evaluation = api.create_evaluation(model, project_data['validation dataset'])\n",
    "            api.ok(evaluation)\n",
    "            model_data['valid evaluation'] = evaluation['resource']\n",
    "        if 'train evaluation' not in model_data:\n",
    "            evaluation = api.create_evaluation(model, model_data['train dataset'])\n",
    "            api.ok(evaluation)\n",
    "            model_data['train evaluation'] = evaluation['resource']\n",
    "        print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(project_data)\n",
    "data_save(project_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepnet_train_auc=[]\n",
    "ensemble_train_auc=[]\n",
    "deepnet_valid_auc=[]\n",
    "ensemble_valid_auc=[]\n",
    "for size in training_sizes:\n",
    "    evaluation = api.get_evaluation(project_data['models'][size]['deepnet']['train evaluation'])\n",
    "    auc = evaluation['object']['result']['model']['average_area_under_roc_curve']\n",
    "    deepnet_train_auc.append(auc)\n",
    "    \n",
    "    evaluation = api.get_evaluation(project_data['models'][size]['ensemble']['train evaluation'])\n",
    "    auc = evaluation['object']['result']['model']['average_area_under_roc_curve']\n",
    "    ensemble_train_auc.append(auc)\n",
    "    \n",
    "    evaluation = api.get_evaluation(project_data['models'][size]['deepnet']['valid evaluation'])\n",
    "    auc = evaluation['object']['result']['model']['average_area_under_roc_curve']\n",
    "    deepnet_valid_auc.append(auc)\n",
    "    \n",
    "    evaluation = api.get_evaluation(project_data['models'][size]['ensemble']['valid evaluation'])\n",
    "    auc = evaluation['object']['result']['model']['average_area_under_roc_curve']\n",
    "    ensemble_valid_auc.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(ensemble_valid_auc)\n",
    "pprint(deepnet_valid_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.subplots(3,1, figsize=(18, 13))\n",
    "plt.subplots_adjust(hspace = 0.3)\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(training_sizes, deepnet_valid_auc, label=\"Deepnet\")\n",
    "plt.plot(training_sizes, ensemble_valid_auc, label=\"Ensemble\")\n",
    "plt.xlabel('training set size')\n",
    "plt.ylabel('AUC')\n",
    "plt.title('Learning Curve: Deepnet vs Ensemble')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(training_sizes, deepnet_train_auc, label=\"training\")\n",
    "plt.plot(training_sizes, deepnet_valid_auc, label=\"dev\")\n",
    "plt.plot([0,150000],[0.87, 0.87])\n",
    "plt.xlabel('training set size')\n",
    "plt.ylabel('AUC')\n",
    "plt.title('Deepnet Learning Curve: dev vs training')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(training_sizes, ensemble_train_auc, label=\"training\")\n",
    "plt.plot(training_sizes, ensemble_valid_auc, label=\"dev\")\n",
    "plt.plot([0,150000],[0.87, 0.87])\n",
    "plt.xlabel('training set size')\n",
    "plt.ylabel('AUC')\n",
    "plt.title('Esemble Learning Curve: dev vs training')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_all(project_data):\n",
    "    for size in project_data['models']:\n",
    "        for model_type in project_data['models'][size]:\n",
    "            model_data = project_data['models'][size][model_type]\n",
    "            if model_type == 'ensemble':\n",
    "                api.delete_ensemble(model_data['bigml model'])\n",
    "            if model_type == 'deepnet':\n",
    "                api.delete_deepnet(model_data['bigml model'])\n",
    "            api.delete_evaluation(model_data['valid evaluation'])\n",
    "            api.delete_evaluation(model_data['train evaluation'])     \n",
    "    for size in project_data['train datasets']:\n",
    "        api.delete_dataset(project_data['train datasets'][size])\n",
    "    for size in project_data['train sources']:\n",
    "        api.delete_source(project_data['train sources'][size])\n",
    "    api.delete_dataset(project_data['validation dataset'])\n",
    "    api.delete_source(project_data['validation source'])\n",
    "    project_data={}\n",
    "    data_save(project_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_all(project_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Format de la Cellule Texte Brut",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
