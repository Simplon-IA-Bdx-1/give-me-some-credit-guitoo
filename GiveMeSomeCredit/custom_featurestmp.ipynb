{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning data and creating custom features for Give Me Some Credit Kaggle Challenge\n",
    "\n",
    "1. Cleaning the monthly income from NA values\n",
    "2. Clean the debt ratio by replacing NA by the mean (Should ideally be done after splitting and the mean should be calculated on the training set if you want to do an evaluation)\n",
    "3. Creating a montlhy debt feature\n",
    "    * monthly income multiplied by debt ratio if income is not 0\n",
    "    * debt ratio if income is 0\n",
    "4. Create a Balanced Income feature that take into account Income and debt ratio\n",
    "    * Set income to 0 when negative.\n",
    "5. Clean the number of dependents feature\n",
    "    * set NA to zero\n",
    "6. Create a Blanced Income per household members feature\n",
    "7. Cleaning the Number of Times Late feature\n",
    "    * Create a custom categorical feature that contains 2 different tags for each row that contains a Number of time late of either 96 or 98\n",
    "    * Remove the 96 and 98 values (Replacing those values by NA or some other justifiable value)\n",
    "8. Add a feature that compute the weighted sum of the number of time late per duration\n",
    "    * weight of 3 for 90 days and more\n",
    "    * weight of 2 for 60 to 89 days\n",
    "    * weight of 1 for 30 to 59 days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame, read_csv, to_numeric\n",
    "from sklearn.model_selection import train_test_split\n",
    "from bigml.api import BigML\n",
    "import kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = False   #Do we split the data?\n",
    "compression = True  #Do we compress the csv files?\n",
    "send_to_BigML = True\n",
    "build_model = True\n",
    "\n",
    "version='v1.2'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading csv files as data frames\n",
    "\n",
    "Files must be placed in the same directory as this file. Alternatively, modify the relative path to those files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd\n",
    "!ls\n",
    "fulltrain=read_csv('./cs-training.csv',index_col=0)\n",
    "test=read_csv('./cs-test.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reordering the objective field column to the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(fulltrain))\n",
    "fulltrain=fulltrain[[c for c in fulltrain if c != 'SeriousDlqin2yrs']+['SeriousDlqin2yrs']]\n",
    "print(list(fulltrain))\n",
    "if not validation:\n",
    "    test=test[[c for c in fulltrain if c != 'SeriousDlqin2yrs']+['SeriousDlqin2yrs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(validation==True):\n",
    "    train80, test20 = train_test_split(fulltrain, test_size=0.2)\n",
    "    data_sets=[train80,test20]\n",
    "else:\n",
    "    data_sets=[fulltrain,test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting the values in monthly income\n",
    "Set NaN to 0 in the monthly income column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(DataFrame.fillna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in data_sets:\n",
    "    df.loc[:,'MonthlyIncome'].fillna(0, inplace=True)\n",
    "    \n",
    "data_sets[0].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Debt ratio\n",
    "Set NA values to the mean from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean=data_sets[0]['DebtRatio'].mean\n",
    "\n",
    "for df in data_sets:\n",
    "    df.loc[:,'DebtRatio'].fillna(mean, inplace=True)\n",
    "    \n",
    "data_sets[0].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a new column for monthly debt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(DataFrame.insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for df in data_sets:\n",
    "    df.insert(5,\"MonthlyDebt\",0)\n",
    "data_sets[0].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: mask Should help here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in data_sets:\n",
    "    df.loc[:,'MonthlyDebt']=df['DebtRatio']*df['MonthlyIncome']\n",
    "    df.loc[df['MonthlyIncome'] == 0,'MonthlyDebt']=df.loc[df['MonthlyIncome'] == 0,'DebtRatio']\n",
    "    df.loc[df['MonthlyIncome'] == 0,'DebtRatio']=0\n",
    "\n",
    "\n",
    "data_sets[0][['MonthlyDebt','DebtRatio','MonthlyIncome']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a balanced Income feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in data_sets:\n",
    "    df.insert(6,'BalancedIncome',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for df in data_sets:\n",
    "    income_positive = df['MonthlyIncome'] - df['MonthlyDebt']>0\n",
    "    df.loc[income_positive,'BalancedIncome']= df.loc[income_positive,'MonthlyIncome'] - df.loc[income_positive,'MonthlyDebt']\n",
    "\n",
    "data_sets[0].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the number of dependents column\n",
    "Set to 0 the number of dependents when not available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in data_sets:\n",
    "    df.loc[:,'NumberOfDependents'].fillna(0, inplace=True)\n",
    "    df.loc[:,'NumberOfDependents']=to_numeric(df['NumberOfDependents'],downcast='integer')\n",
    "    \n",
    "data_sets[0][['NumberOfDependents']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a balanced income per household members feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in data_sets:\n",
    "    df.insert(7,'IncomePerHouseholdMember',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in data_sets:\n",
    "    df.loc[:,'IncomePerHouseholdMember']= df['BalancedIncome'] / (df['NumberOfDependents']+1)\n",
    "data_sets[0][['IncomePerHouseholdMember']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a \"number of times late\" categorical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in data_sets:\n",
    "    df.insert(8,'LateCategory',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_sets[0].loc[data_sets[0]['NumberOfTimes90DaysLate']==98,['LateCategory','NumberOfTimes90DaysLate']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for df in data_sets:\n",
    "    df.loc[:,'LateCategory']=\"L0\"\n",
    "    df.loc[df['NumberOfTimes90DaysLate'] == 98,'LateCategory']=\"L98\"\n",
    "    df.loc[df['NumberOfTimes90DaysLate'] == 96,'LateCategory']=\"L96\"\n",
    "    df.loc[(df['NumberOfTimes90DaysLate'] == 98) | (df['NumberOfTimes90DaysLate'] == 96),\n",
    "              ['NumberOfTime30-59DaysPastDueNotWorse','NumberOfTime60-89DaysPastDueNotWorse','NumberOfTimes90DaysLate']]=\"NA\"\n",
    "              \n",
    "data_sets[0].loc[(data_sets[0]['LateCategory']=='L96') | (data_sets[0]['LateCategory']=='L98'),['LateCategory','NumberOfTimes90DaysLate']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add a \"Late score\" feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in data_sets:\n",
    "    df.insert(0,'LateScore',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in data_sets:\n",
    "    df.loc[:,'LateScore']=3*df['NumberOfTimes90DaysLate']+2*df['NumberOfTime60-89DaysPastDueNotWorse']+df['NumberOfTime30-59DaysPastDueNotWorse']\n",
    "    \n",
    "data_sets[0][['LateScore']].head(10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove the features we don't need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(data_sets[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in data_sets:\n",
    "    df.drop('NumberOfTime30-59DaysPastDueNotWorse', axis=1, inplace=True)\n",
    "    df.drop('NumberOfTime60-89DaysPastDueNotWorse', axis=1, inplace=True)\n",
    "    df.drop('NumberOfTimes90DaysLate', axis=1, inplace=True)\n",
    "\n",
    "print(list(data_sets[0])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the data frames as csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if compression:\n",
    "    compress='.bz2'\n",
    "else:\n",
    "    compress=''\n",
    "\n",
    "filenames = [\"\",\"\"]\n",
    "    \n",
    "if validation:\n",
    "    filenames[0]= 'gmsc-train80-' + version + '.csv'+ compress\n",
    "    filenames[1]= 'gmsc-valid20-' + version + '.csv'+ compress\n",
    "else:\n",
    "    filenames[0]= 'gmsc-fulltrain-' + version + '.csv'+ compress\n",
    "    filenames[1]= 'gmsc-test.csv-' + version + '.csv'+ compress\n",
    "\n",
    "for i in range(0,2):\n",
    "    data_sets[i].to_csv(filenames[i],index_label='Id')\n",
    "                        \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send the data to BigML and create an ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if send_to_BigML:\n",
    "    api = BigML(project='project/5d94a428eba31d460c00023f')\n",
    "\n",
    "    if validation:\n",
    "        train_src = api.create_source('gmsc-train80' + str(version)+ '.csv'+compress)\n",
    "        api.ok(train_src)\n",
    "        test_src = api.create_source('gmsc-valid20' + str(version)+ '.csv'+compress)\n",
    "        api.ok(test_src)\n",
    "    else:\n",
    "        train_src = api.create_source('gmsc-fulltrain' + str(version)+ '.csv'+compress)\n",
    "        api.ok(train_src)\n",
    "        test_src = api.create_source('gmsc-test' + str(version)+ '.csv'+compress)\n",
    "        api.ok(test_src)\n",
    "\n",
    "    print(\"Sources created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if send_to_BigML:\n",
    "    train_ds = api.create_dataset(train_src)\n",
    "    api.ok(train_ds)\n",
    "    test_ds = api.create_dataset(test_src)\n",
    "    api.ok(test_ds)\n",
    "    print(\"Data sets created\")\n",
    "    model = api.create_ensemble(train_ds)\n",
    "    api.ok(model)\n",
    "    print(\"Model created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation or test batch prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_file='./gsmc_predictions-{}.csv'.format(version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if validation:\n",
    "#    evaluation = api.get_evaluation(model, test_ds)\n",
    "#    api.ok(evaluation)\n",
    "#    api.pprint(evaluation['object']['result'])\n",
    "#else:\n",
    "if send_to_BigML:\n",
    "    batch_prediction = api.create_batch_prediction(model, test_ds, {\n",
    "        \"name\": \"my batch prediction\" + version,\n",
    "        \"all_fields\": True,\n",
    "        \"header\": True,\n",
    "        \"confidence\": True,\n",
    "        \"probabilities\": True}                      )\n",
    "    api.ok(batch_prediction)\n",
    "    api.download_batch_prediction(batch_prediction,\n",
    "    filename=prediction_file)\n",
    "    print('batch prediction:Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send prediction to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=read_csv(prediction_file,index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_prediction=DataFrame()\n",
    "if validation:\n",
    "    prediction['absolute_error']=(prediction['1 probability']-prediction['SeriousDlqin2yrs']).abs()\n",
    "    prediction = prediction.sort_values(by='absolute_error', ascending=False)\n",
    "else:\n",
    "    kaggle_prediction['Id']=prediction['Id']\n",
    "    kaggle_prediction['Probability']=prediction['1 probability']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_prediction_file=\"kaggleprediction.csv\"\n",
    "kaggle_prediction.to_csv(kaggle_prediction_file,index=False)\n",
    "kaggle.api.competition_submit(kaggle_prediction_file, \"Ensemble-\" + str(version), \"GiveMeSomeCredit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
