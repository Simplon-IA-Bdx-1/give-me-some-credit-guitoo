{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep track of your BIGML models with storemagic and pickle\n",
    "The Jupyter extension storemagic allows you to store python objects in a datastore\n",
    "\n",
    "https://ipython.readthedocs.io/en/stable/config/extensions/storemagic.html\n",
    "\n",
    "This notebook will present a methology that can help you\n",
    "* keeping track of your models between files\n",
    "* avoiding needlessly rebuilding existing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is an exemple of the data structure you could use.\n",
    "\n",
    "Save the filenames of the fulltrain and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data={}\n",
    "project_data['fulltrain file']='full.csv'\n",
    "project_data['test file']='test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataset ids after creation in bigml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data['bigml fulltrain ds']='dataset/156755'\n",
    "project_data['bigml test ds']='dataset/156755'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After splitting in BigML, save the id of the training and validation data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bigml fulltrain ds': 'dataset/156755',\n",
      " 'bigml test ds': 'dataset/156755',\n",
      " 'fulltrain file': 'full.csv',\n",
      " 'models': [{'bigml trainind ds': 'dataset/123456',\n",
      "             'bigml validation ds': 'dataset/234567',\n",
      "             'model type': 'ensemble',\n",
      "             'name': 'my ensemble'},\n",
      "            {'bigml trainind ds': 'dataset/123456',\n",
      "             'bigml validation ds': 'dataset/234567',\n",
      "             'model type': 'deepnet',\n",
      "             'name': 'my deepnet'}],\n",
      " 'test file': 'test.csv'}\n"
     ]
    }
   ],
   "source": [
    "project_data['models']=[]\n",
    "project_data['models'].append({'model type':'ensemble'})\n",
    "project_data['models'][0]['bigml trainind ds'] = 'dataset/123456'\n",
    "project_data['models'][0]['bigml validation ds'] = 'dataset/234567'\n",
    "project_data['models'][0]['name'] = 'my ensemble'\n",
    "\n",
    "project_data['models'].append({'model type':'deepnet'})\n",
    "project_data['models'][1]['bigml trainind ds'] = 'dataset/123456'\n",
    "project_data['models'][1]['bigml validation ds'] = 'dataset/234567'\n",
    "project_data['models'][1]['name'] = 'my deepnet'\n",
    "pprint(project_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add comment on your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data['models'][0]['comment'] = 'This is a ensemble model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'project_data' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store project_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let say you do your training in an other file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data={}\n",
    "project_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get your data back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r project_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You get back every information necessary for your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bigml fulltrain ds': 'dataset/156755',\n",
      " 'bigml test ds': 'dataset/156755',\n",
      " 'fulltrain file': 'full.csv',\n",
      " 'models': [{'bigml trainind ds': 'dataset/123456',\n",
      "             'bigml validation ds': 'dataset/234567',\n",
      "             'comment': 'This is a ensemble model',\n",
      "             'model type': 'ensemble',\n",
      "             'name': 'my ensemble'},\n",
      "            {'bigml trainind ds': 'dataset/123456',\n",
      "             'bigml validation ds': 'dataset/234567',\n",
      "             'model type': 'deepnet',\n",
      "             'name': 'my deepnet'}],\n",
      " 'test file': 'test.csv'}\n"
     ]
    }
   ],
   "source": [
    "pprint(project_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the id of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data['models'][0]['bigml model'] = 'ensemble/213456'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data['models'].append({'model type':'ensemble'})\n",
    "project_data['models'][-1]['name'] = 'my ensemble 2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train all ensemble models not already trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'project_data' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store -r project_data\n",
    "ensembles = [model for model in project_data['models'] if model['model type'] == 'ensemble']\n",
    "for model in ensembles:\n",
    "    if 'bigml model' not in model:\n",
    "        #train your ensemble\n",
    "        model['bigml model'] = 'ensemble/456789'\n",
    "%store project_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'bigml model': 'ensemble/213456',\n",
      "  'bigml trainind ds': 'dataset/123456',\n",
      "  'bigml validation ds': 'dataset/234567',\n",
      "  'comment': 'This is a ensemble model',\n",
      "  'model type': 'ensemble',\n",
      "  'name': 'my ensemble'},\n",
      " {'bigml trainind ds': 'dataset/123456',\n",
      "  'bigml validation ds': 'dataset/234567',\n",
      "  'model type': 'deepnet',\n",
      "  'name': 'my deepnet'},\n",
      " {'bigml model': 'ensemble/456789',\n",
      "  'model type': 'ensemble',\n",
      "  'name': 'my ensemble 2'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(project_data['models'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a batch prediction for all your model if none exist yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'project_data' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store -r project_data\n",
    "for model in project_data['models']:\n",
    "    if 'prediction file' not in model:\n",
    "        #do batch prediction on model['bigml model'] with model['bigml validation ds']\n",
    "        model['valid batchpred'] = 'batchprediction/54521238'\n",
    "        model['valid batchpred file'] = 'valid-prediction-' + model['name'] + '.csv'\n",
    "%store project_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bigml fulltrain ds': 'dataset/156755',\n",
      " 'bigml test ds': 'dataset/156755',\n",
      " 'fulltrain file': 'full.csv',\n",
      " 'models': [{'bigml model': 'ensemble/213456',\n",
      "             'bigml trainind ds': 'dataset/123456',\n",
      "             'bigml validation ds': 'dataset/234567',\n",
      "             'comment': 'This is a ensemble model',\n",
      "             'model type': 'ensemble',\n",
      "             'name': 'my ensemble',\n",
      "             'valid batchpred': 'batchprediction/54521238',\n",
      "             'valid batchpred file': 'valid-prediction-my ensemble.csv'},\n",
      "            {'bigml trainind ds': 'dataset/123456',\n",
      "             'bigml validation ds': 'dataset/234567',\n",
      "             'model type': 'deepnet',\n",
      "             'name': 'my deepnet',\n",
      "             'valid batchpred': 'batchprediction/54521238',\n",
      "             'valid batchpred file': 'valid-prediction-my deepnet.csv'},\n",
      "            {'bigml model': 'ensemble/456789',\n",
      "             'model type': 'ensemble',\n",
      "             'name': 'my ensemble 2',\n",
      "             'valid batchpred': 'batchprediction/54521238',\n",
      "             'valid batchpred file': 'valid-prediction-my ensemble 2.csv'}],\n",
      " 'test file': 'test.csv'}\n"
     ]
    }
   ],
   "source": [
    "pprint(project_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting changes\n",
    "If you change your features and upload new data sets, your model and prediction need to be refreshed.\n",
    "\n",
    "Here is an exemple with the refresh of a batch prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "%store -r project_data\n",
    "for model in project_data['models']\n",
    "    if 'valid batchpred' not in model:\n",
    "        do_prediction = True\n",
    "    else:\n",
    "        batch_prediction = api.get_batch_prediction(model['valid batchpred'])\n",
    "        model_changed = batch_prediction['object']['ensemble'] != model['bigml model']\n",
    "        do_prediction = model_changed\n",
    "\n",
    "    if do_prediction:\n",
    "        api.delete_batch_prediction(batch_prediction)\n",
    "        batch_prediction = api.create_batch_prediction(model['bigml model'], model['bigml validation ds'])\n",
    "        model['valid batchpred']=batch_prediction['resource']\n",
    "%store project_data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the batch prediction doesn't exist or if your model has changed, we delete the previous batch prediction and redo a batch prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other storemagic commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all stored variables\n",
    "```\n",
    "%store -z\n",
    "```\n",
    "Load all variables\n",
    "```\n",
    "%store -r\n",
    "```\n",
    "Remove your variable from the datastore\n",
    "```\n",
    "%store -d project_data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store your data in a file with pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storemagic is local to your notebook server.\n",
    "\n",
    "If you need to exchange data between several Jupyter servers you can use pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load, dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a file name for your project.\n",
    "You will store the information of your models in that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'gmsc'\n",
    "version = '1.1'\n",
    "jar_filename = project + '-' + version + '-picklejar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gmsc-1.1-picklejar'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jar_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(jar_filename, 'wb') as file:\n",
    "    dump(project_data,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data={}\n",
    "project_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(jar_filename, 'rb') as file:\n",
    "    project_data = load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fulltrain file': 'full.csv',\n",
       " 'test file': 'test.csv',\n",
       " 'bigml fulltrain ds': 'dataset/156755',\n",
       " 'bigml test ds': 'dataset/156755',\n",
       " 'models': [{'model type': 'ensemble',\n",
       "   'bigml trainind ds': 'dataset/123456',\n",
       "   'bigml validation ds': 'dataset/234567',\n",
       "   'name': 'my ensemble',\n",
       "   'comment': 'This is a ensemble model',\n",
       "   'bigml model': 'ensemble/213456',\n",
       "   'valid batchpred': 'batchprediction/54521238',\n",
       "   'valid batchpred file': 'valid-prediction-my ensemble.csv'},\n",
       "  {'model type': 'deepnet',\n",
       "   'bigml trainind ds': 'dataset/123456',\n",
       "   'bigml validation ds': 'dataset/234567',\n",
       "   'name': 'my deepnet',\n",
       "   'valid batchpred': 'batchprediction/54521238',\n",
       "   'valid batchpred file': 'valid-prediction-my deepnet.csv'},\n",
       "  {'model type': 'ensemble',\n",
       "   'name': 'my ensemble 2',\n",
       "   'bigml model': 'ensemble/456789',\n",
       "   'valid batchpred': 'batchprediction/54521238',\n",
       "   'valid batchpred file': 'valid-prediction-my ensemble 2.csv'}]}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
