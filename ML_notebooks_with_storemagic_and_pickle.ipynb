{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep track of your BIGML models with storemagic, pickle and json\n",
    "The Jupyter extension storemagic allows you to store python objects in a datastore\n",
    "\n",
    "https://ipython.readthedocs.io/en/stable/config/extensions/storemagic.html\n",
    "\n",
    "This notebook will present a methology that can help you\n",
    "* keeping track of your models between files\n",
    "* avoiding needlessly rebuilding existing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is an exemple of the data structure you could use.\n",
    "\n",
    "Save the filenames of the fulltrain and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data={}\n",
    "project_data['fulltrain file']='full.csv'\n",
    "project_data['test file']='test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the dataset ids after creation in bigml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data['bigml fulltrain ds']='dataset/156755'\n",
    "project_data['bigml test ds']='dataset/156755'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After splitting in BigML, save the id of the training and validation data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bigml fulltrain ds': 'dataset/156755',\n",
      " 'bigml test ds': 'dataset/156755',\n",
      " 'fulltrain file': 'full.csv',\n",
      " 'models': [{'bigml trainind ds': 'dataset/123456',\n",
      "             'bigml validation ds': 'dataset/234567',\n",
      "             'model type': 'ensemble',\n",
      "             'name': 'my ensemble'},\n",
      "            {'bigml trainind ds': 'dataset/123456',\n",
      "             'bigml validation ds': 'dataset/234567',\n",
      "             'model type': 'deepnet',\n",
      "             'name': 'my deepnet'}],\n",
      " 'test file': 'test.csv'}\n"
     ]
    }
   ],
   "source": [
    "project_data['models']=[]\n",
    "project_data['models'].append({'model type':'ensemble'})\n",
    "project_data['models'][0]['bigml trainind ds'] = 'dataset/123456'\n",
    "project_data['models'][0]['bigml validation ds'] = 'dataset/234567'\n",
    "project_data['models'][0]['name'] = 'my ensemble'\n",
    "\n",
    "project_data['models'].append({'model type':'deepnet'})\n",
    "project_data['models'][1]['bigml trainind ds'] = 'dataset/123456'\n",
    "project_data['models'][1]['bigml validation ds'] = 'dataset/234567'\n",
    "project_data['models'][1]['name'] = 'my deepnet'\n",
    "pprint(project_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add comment on your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data['models'][0]['comment'] = 'This is a ensemble model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your data with storemagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'project_data' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store project_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let say you do your training in an other file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data={}\n",
    "project_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get your data back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r project_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You get back every information necessary for your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bigml fulltrain ds': 'dataset/156755',\n",
      " 'bigml test ds': 'dataset/156755',\n",
      " 'fulltrain file': 'full.csv',\n",
      " 'models': [{'bigml trainind ds': 'dataset/123456',\n",
      "             'bigml validation ds': 'dataset/234567',\n",
      "             'comment': 'This is a ensemble model',\n",
      "             'model type': 'ensemble',\n",
      "             'name': 'my ensemble'},\n",
      "            {'bigml trainind ds': 'dataset/123456',\n",
      "             'bigml validation ds': 'dataset/234567',\n",
      "             'model type': 'deepnet',\n",
      "             'name': 'my deepnet'}],\n",
      " 'test file': 'test.csv'}\n"
     ]
    }
   ],
   "source": [
    "pprint(project_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the id of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data['models'][0]['bigml model'] = 'ensemble/213456'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data['models'].append({'model type':'ensemble'})\n",
    "project_data['models'][-1]['name'] = 'my ensemble 2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use list comprehension to select models by type.\n",
    "\n",
    "Train all ensemble models not already trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'project_data' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store -r project_data\n",
    "ensembles = [model for model in project_data['models'] if model['model type'] == 'ensemble']\n",
    "for model in ensembles:\n",
    "    if 'bigml model' not in model:\n",
    "        #train your ensemble\n",
    "        model['bigml model'] = 'ensemble/456789'\n",
    "%store project_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'bigml model': 'ensemble/213456',\n",
      "  'bigml trainind ds': 'dataset/123456',\n",
      "  'bigml validation ds': 'dataset/234567',\n",
      "  'comment': 'This is a ensemble model',\n",
      "  'model type': 'ensemble',\n",
      "  'name': 'my ensemble'},\n",
      " {'bigml trainind ds': 'dataset/123456',\n",
      "  'bigml validation ds': 'dataset/234567',\n",
      "  'model type': 'deepnet',\n",
      "  'name': 'my deepnet'},\n",
      " {'bigml model': 'ensemble/456789',\n",
      "  'model type': 'ensemble',\n",
      "  'name': 'my ensemble 2'}]\n"
     ]
    }
   ],
   "source": [
    "pprint(project_data['models'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a batch prediction for all your model if none exist yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'project_data' (dict)\n"
     ]
    }
   ],
   "source": [
    "%store -r project_data\n",
    "for model in project_data['models']:\n",
    "    if 'prediction file' not in model:\n",
    "        #do batch prediction on model['bigml model'] with model['bigml validation ds']\n",
    "        model['valid batchpred'] = 'batchprediction/54521238'\n",
    "        model['valid batchpred file'] = 'valid-prediction-' + model['name'] + '.csv'\n",
    "%store project_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bigml fulltrain ds': 'dataset/156755',\n",
      " 'bigml test ds': 'dataset/156755',\n",
      " 'fulltrain file': 'full.csv',\n",
      " 'models': [{'bigml model': 'ensemble/213456',\n",
      "             'bigml trainind ds': 'dataset/123456',\n",
      "             'bigml validation ds': 'dataset/234567',\n",
      "             'comment': 'This is a ensemble model',\n",
      "             'model type': 'ensemble',\n",
      "             'name': 'my ensemble',\n",
      "             'valid batchpred': 'batchprediction/54521238',\n",
      "             'valid batchpred file': 'valid-prediction-my ensemble.csv'},\n",
      "            {'bigml trainind ds': 'dataset/123456',\n",
      "             'bigml validation ds': 'dataset/234567',\n",
      "             'model type': 'deepnet',\n",
      "             'name': 'my deepnet',\n",
      "             'valid batchpred': 'batchprediction/54521238',\n",
      "             'valid batchpred file': 'valid-prediction-my deepnet.csv'},\n",
      "            {'bigml model': 'ensemble/456789',\n",
      "             'model type': 'ensemble',\n",
      "             'name': 'my ensemble 2',\n",
      "             'valid batchpred': 'batchprediction/54521238',\n",
      "             'valid batchpred file': 'valid-prediction-my ensemble 2.csv'}],\n",
      " 'test file': 'test.csv'}\n"
     ]
    }
   ],
   "source": [
    "pprint(project_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting changes\n",
    "If you change your features and upload new data sets, your model and prediction need to be refreshed.\n",
    "\n",
    "Here is an exemple with the refresh of a batch prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "%store -r project_data\n",
    "for model in project_data['models']\n",
    "    if 'valid batchpred' not in model:\n",
    "        do_prediction = True\n",
    "    else:\n",
    "        batch_prediction = api.get_batch_prediction(model['valid batchpred'])\n",
    "        model_changed = batch_prediction['object']['ensemble'] != model['bigml model']\n",
    "        do_prediction = model_changed\n",
    "\n",
    "    if do_prediction:\n",
    "        api.delete_batch_prediction(batch_prediction)\n",
    "        batch_prediction = api.create_batch_prediction(model['bigml model'], model['bigml validation ds'])\n",
    "        model['valid batchpred']=batch_prediction['resource']\n",
    "%store project_data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the batch prediction doesn't exist or if your model has changed, we delete the previous batch prediction and redo a batch prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other storemagic commands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all stored variables\n",
    "```\n",
    "%store -z\n",
    "```\n",
    "Load all variables\n",
    "```\n",
    "%store -r\n",
    "```\n",
    "Remove your variable from the datastore\n",
    "```\n",
    "%store -d project_data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store your data in a file with pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storemagic is local to your notebook server.\n",
    "\n",
    "If you need to exchange data between several Jupyter servers you can use pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load, dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a file name for your project.\n",
    "You will store the information of your models in that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'gmsc'\n",
    "version = '1.1'\n",
    "jar_filename = project + '-' + version + '-picklejar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gmsc-1.1-picklejar'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jar_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(jar_filename, 'wb') as file:\n",
    "    dump(project_data,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data={}\n",
    "project_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(jar_filename, 'rb') as file:\n",
    "    project_data = load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fulltrain file': 'full.csv',\n",
       " 'test file': 'test.csv',\n",
       " 'bigml fulltrain ds': 'dataset/156755',\n",
       " 'bigml test ds': 'dataset/156755',\n",
       " 'models': [{'model type': 'ensemble',\n",
       "   'bigml trainind ds': 'dataset/123456',\n",
       "   'bigml validation ds': 'dataset/234567',\n",
       "   'name': 'my ensemble',\n",
       "   'comment': 'This is a ensemble model',\n",
       "   'bigml model': 'ensemble/213456',\n",
       "   'valid batchpred': 'batchprediction/54521238',\n",
       "   'valid batchpred file': 'valid-prediction-my ensemble.csv'},\n",
       "  {'model type': 'deepnet',\n",
       "   'bigml trainind ds': 'dataset/123456',\n",
       "   'bigml validation ds': 'dataset/234567',\n",
       "   'name': 'my deepnet',\n",
       "   'valid batchpred': 'batchprediction/54521238',\n",
       "   'valid batchpred file': 'valid-prediction-my deepnet.csv'},\n",
       "  {'model type': 'ensemble',\n",
       "   'name': 'my ensemble 2',\n",
       "   'bigml model': 'ensemble/456789',\n",
       "   'valid batchpred': 'batchprediction/54521238',\n",
       "   'valid batchpred file': 'valid-prediction-my ensemble 2.csv'}]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use save and load functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path \n",
    "def data_save(project_data):\n",
    "    with open(jar_filename, 'wb') as file:\n",
    "        dump(project_data,file)\n",
    "def data_load():\n",
    "    if path.exists(jar_filename):\n",
    "        with open(jar_filename, 'rb') as file:\n",
    "            project_data = load(file)\n",
    "        return project_data\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the file doesn't exist, data_load() return an empty dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_save(project_data)\n",
    "project_data = data_load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store your data in a file with json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'gmsc'\n",
    "version = '1.1'\n",
    "json_filename = project + '-' + version + '.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(project_data, open(json_filename,\"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_data = json.load(open(json_filename,\"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_save(data):\n",
    "    with open(jar_filename, 'wb') as file:\n",
    "        json.dump(data, open(json_filename,\"w\"))\n",
    "def json_load():\n",
    "    if path.exists(jar_filename):\n",
    "        with open(jar_filename, 'rb') as file:\n",
    "            data = json.load(open(json_filename,\"r\"))\n",
    "        return data\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_save(project_data)\n",
    "project_data = {}\n",
    "project_data = json_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model type': 'ensemble',\n",
       " 'bigml trainind ds': 'dataset/123456',\n",
       " 'bigml validation ds': 'dataset/234567',\n",
       " 'name': 'my ensemble',\n",
       " 'comment': 'This is a ensemble model',\n",
       " 'bigml model': 'ensemble/213456',\n",
       " 'valid batchpred': 'batchprediction/54521238',\n",
       " 'valid batchpred file': 'valid-prediction-my ensemble.csv'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_data['models'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"fulltrain file\": \"full.csv\", \"test file\": \"test.csv\", \"bigml fulltrain ds\": \"dataset/156755\", \"bigml test ds\": \"dataset/156755\", \"models\": [{\"model type\": \"ensemble\", \"bigml trainind ds\": \"dataset/123456\", \"bigml validation ds\": \"dataset/234567\", \"name\": \"my ensemble\", \"comment\": \"This is a ensemble model\", \"bigml model\": \"ensemble/213456\", \"valid batchpred\": \"batchprediction/54521238\", \"valid batchpred file\": \"valid-prediction-my ensemble.csv\"}, {\"model type\": \"deepnet\", \"bigml trainind ds\": \"dataset/123456\", \"bigml validation ds\": \"dataset/234567\", \"name\": \"my deepnet\", \"valid batchpred\": \"batchprediction/54521238\", \"valid batchpred file\": \"valid-prediction-my deepnet.csv\"}, {\"model type\": \"ensemble\", \"name\": \"my ensemble 2\", \"bigml model\": \"ensemble/456789\", \"valid batchpred\": \"batchprediction/54521238\", \"valid batchpred file\": \"valid-prediction-my ensemble 2.csv\"}]}"
     ]
    }
   ],
   "source": [
    "!cat {json_filename}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: ## Save your models with Joblib\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(model, filename)\n",
    "loaded_model = joblib.load(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
